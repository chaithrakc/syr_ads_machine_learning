{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"neural_network.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1I8Y_UIXWaOXLuvpJHOdMcbXIGloplLSM","authorship_tag":"ABX9TyN7cY3TIUaOU56ASufwWteC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["MultiLayer Perceptron for Titanic Data"],"metadata":{"id":"YdgQf1NyONLf"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"dgXEnSifOA5M","executionInfo":{"status":"ok","timestamp":1650379418529,"user_tz":240,"elapsed":2880,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"outputs":[],"source":["# importing required libraries\n","\n","import pandas as pd\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n"]},{"cell_type":"markdown","source":["Loading the Data"],"metadata":{"id":"OHAevCt6PHuA"}},{"cell_type":"code","source":["train = pd.read_csv('/content/drive/Othercomputers/My Laptop/syr_ads_ist707/week10neural_network/lab10/titanic-train.csv')\n","train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AIaqi-JjOXAM","executionInfo":{"status":"ok","timestamp":1650379426721,"user_tz":240,"elapsed":2258,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"52c60e0b-3329-4a57-f474-6e752c984c61"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(891, 11)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"qqu4S-gyPJUU","executionInfo":{"status":"ok","timestamp":1650379427544,"user_tz":240,"elapsed":28,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"403c7792-0542-4af8-f0da-c5cb9231a030"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n","0            1         0       3    male  22.0      1      0   \n","1            2         1       1  female  38.0      1      0   \n","2            3         1       3  female  26.0      0      0   \n","3            4         1       1  female  35.0      1      0   \n","4            5         0       3    male  35.0      0      0   \n","\n","             Ticket     Fare Cabin Embarked  \n","0         A/5 21171   7.2500   NaN        S  \n","1          PC 17599  71.2833   C85        C  \n","2  STON/O2. 3101282   7.9250   NaN        S  \n","3            113803  53.1000  C123        S  \n","4            373450   8.0500   NaN        S  "],"text/html":["\n","  <div id=\"df-302f54ef-2787-499d-92d4-b0f9ff272e6d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-302f54ef-2787-499d-92d4-b0f9ff272e6d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-302f54ef-2787-499d-92d4-b0f9ff272e6d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-302f54ef-2787-499d-92d4-b0f9ff272e6d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["test = pd.read_csv('/content/drive/Othercomputers/My Laptop/syr_ads_ist707/week10neural_network/lab10/titanic-test.csv')\n","test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ul9OqeYLPdXQ","executionInfo":{"status":"ok","timestamp":1650379430007,"user_tz":240,"elapsed":722,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"4dcd982b-90d2-4c6a-8970-b30221b42958"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(418, 11)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# converting cabin to binary attribute using dummy variable\n","train['Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n","test['Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n","\n","# converting sex cateogorical variable to dummy variable\n","train['Sex'] = train[\"Sex\"].replace({'male':0,'female':1})\n","test['Sex'] = test[\"Sex\"].replace({'male':0,'female':1})"],"metadata":{"id":"kNr2agYOPiTO","executionInfo":{"status":"ok","timestamp":1650379432050,"user_tz":240,"elapsed":4,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["full_data = [train,test]\n","full_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zz4ph38SPkcg","executionInfo":{"status":"ok","timestamp":1650379434404,"user_tz":240,"elapsed":314,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"195743d2-6a25-48ea-e508-18002ccb614e"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch            Ticket  \\\n"," 0              1         0       3    0  22.0      1      0         A/5 21171   \n"," 1              2         1       1    1  38.0      1      0          PC 17599   \n"," 2              3         1       3    1  26.0      0      0  STON/O2. 3101282   \n"," 3              4         1       1    1  35.0      1      0            113803   \n"," 4              5         0       3    0  35.0      0      0            373450   \n"," ..           ...       ...     ...  ...   ...    ...    ...               ...   \n"," 886          887         0       2    0  27.0      0      0            211536   \n"," 887          888         1       1    1  19.0      0      0            112053   \n"," 888          889         0       3    1   NaN      1      2        W./C. 6607   \n"," 889          890         1       1    0  26.0      0      0            111369   \n"," 890          891         0       3    0  32.0      0      0            370376   \n"," \n","         Fare  Cabin Embarked  \n"," 0     7.2500      0        S  \n"," 1    71.2833      1        C  \n"," 2     7.9250      0        S  \n"," 3    53.1000      1        S  \n"," 4     8.0500      0        S  \n"," ..       ...    ...      ...  \n"," 886  13.0000      0        S  \n"," 887  30.0000      1        S  \n"," 888  23.4500      0        S  \n"," 889  30.0000      1        C  \n"," 890   7.7500      0        Q  \n"," \n"," [891 rows x 11 columns],\n","      PassengerId Survived  Pclass  Sex   Age  SibSp  Parch  \\\n"," 0            892        ?       3    0  34.5      0      0   \n"," 1            893        ?       3    1  47.0      1      0   \n"," 2            894        ?       2    0  62.0      0      0   \n"," 3            895        ?       3    0  27.0      0      0   \n"," 4            896        ?       3    1  22.0      1      1   \n"," ..           ...      ...     ...  ...   ...    ...    ...   \n"," 413         1305        ?       3    0   NaN      0      0   \n"," 414         1306        ?       1    1  39.0      0      0   \n"," 415         1307        ?       3    0  38.5      0      0   \n"," 416         1308        ?       3    0   NaN      0      0   \n"," 417         1309        ?       3    0   NaN      1      1   \n"," \n","                  Ticket      Fare  Cabin Embarked  \n"," 0                330911    7.8292      0        Q  \n"," 1                363272    7.0000      0        S  \n"," 2                240276    9.6875      0        Q  \n"," 3                315154    8.6625      0        S  \n"," 4               3101298   12.2875      0        S  \n"," ..                  ...       ...    ...      ...  \n"," 413           A.5. 3236    8.0500      0        S  \n"," 414            PC 17758  108.9000      1        C  \n"," 415  SOTON/O.Q. 3101262    7.2500      0        S  \n"," 416              359309    8.0500      0        S  \n"," 417                2668   22.3583      0        C  \n"," \n"," [418 rows x 11 columns]]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Remove all NULLS in the Age column\n","for dataset in full_data:\n","    age_avg = dataset['Age'].mean()\n","    age_std = dataset['Age'].std()\n","    age_null_count = dataset['Age'].isnull().sum()\n","    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n","    # Next line has been improved to avoid warning\n","    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n","    dataset['Age'] = dataset['Age'].astype(int)"],"metadata":{"id":"O0YOid_IPows","executionInfo":{"status":"ok","timestamp":1650379436552,"user_tz":240,"elapsed":289,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["X_train = train[['Sex','Pclass','Age','SibSp','Parch','Cabin']]\n","Y_train = train['Survived']\n","X_test = test[['Sex','Pclass','Age','SibSp','Parch','Cabin']]"],"metadata":{"id":"HD7ycuw_Pq9X","executionInfo":{"status":"ok","timestamp":1650379438936,"user_tz":240,"elapsed":4,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["MPP"],"metadata":{"id":"iz-HY_2lP5iM"}},{"cell_type":"code","source":["num_classes = 1\n","\n","mlp_classifier = keras.Sequential(\n","    [\n","        keras.Input(shape=X_train.shape[1]),\n","        layers.Dense(9, activation='relu'),\n","        layers.Dense(9, activation='relu'),\n","        layers.Dense(5, activation='relu'),\n","        layers.Dense(num_classes, activation=\"sigmoid\"), # similar to logistic regression in keras\n","    ]\n",")\n","\n","mlp_classifier.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L7pwJZMfP4gm","executionInfo":{"status":"ok","timestamp":1650380142960,"user_tz":240,"elapsed":248,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"bde08e1b-8972-4e75-815b-e64968d6332a"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_23 (Dense)            (None, 9)                 63        \n","                                                                 \n"," dense_24 (Dense)            (None, 9)                 90        \n","                                                                 \n"," dense_25 (Dense)            (None, 5)                 50        \n","                                                                 \n"," dense_26 (Dense)            (None, 1)                 6         \n","                                                                 \n","=================================================================\n","Total params: 209\n","Trainable params: 209\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["batch_size = 128\n","epochs = 300\n","\n","# compiling the ANN - basically setting up the optimizer\n","mlp_classifier.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Fitting the ANN to the training data\n","mlp_classifier.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQKhx7JQQJgJ","executionInfo":{"status":"ok","timestamp":1650380207238,"user_tz":240,"elapsed":14254,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"10f65f92-6464-440c-e80b-634025f077af"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","7/7 [==============================] - 1s 31ms/step - loss: 0.4416 - accuracy: 0.8177 - val_loss: 0.3943 - val_accuracy: 0.8444\n","Epoch 2/300\n","7/7 [==============================] - 0s 9ms/step - loss: 0.4365 - accuracy: 0.8290 - val_loss: 0.3937 - val_accuracy: 0.8556\n","Epoch 3/300\n","7/7 [==============================] - 0s 9ms/step - loss: 0.4327 - accuracy: 0.8315 - val_loss: 0.3979 - val_accuracy: 0.8556\n","Epoch 4/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.8277 - val_loss: 0.3963 - val_accuracy: 0.8667\n","Epoch 5/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.8315 - val_loss: 0.3942 - val_accuracy: 0.8444\n","Epoch 6/300\n","7/7 [==============================] - 0s 18ms/step - loss: 0.4336 - accuracy: 0.8290 - val_loss: 0.3939 - val_accuracy: 0.8556\n","Epoch 7/300\n","7/7 [==============================] - 0s 8ms/step - loss: 0.4324 - accuracy: 0.8315 - val_loss: 0.3930 - val_accuracy: 0.8556\n","Epoch 8/300\n","7/7 [==============================] - 0s 9ms/step - loss: 0.4300 - accuracy: 0.8302 - val_loss: 0.3917 - val_accuracy: 0.8444\n","Epoch 9/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.8315 - val_loss: 0.3920 - val_accuracy: 0.8556\n","Epoch 10/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.8302 - val_loss: 0.3907 - val_accuracy: 0.8556\n","Epoch 11/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.8277 - val_loss: 0.3894 - val_accuracy: 0.8556\n","Epoch 12/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.8277 - val_loss: 0.3897 - val_accuracy: 0.8556\n","Epoch 13/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8290 - val_loss: 0.3885 - val_accuracy: 0.8556\n","Epoch 14/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8302 - val_loss: 0.3874 - val_accuracy: 0.8556\n","Epoch 15/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8302 - val_loss: 0.3874 - val_accuracy: 0.8667\n","Epoch 16/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8290 - val_loss: 0.3873 - val_accuracy: 0.8444\n","Epoch 17/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8327 - val_loss: 0.3880 - val_accuracy: 0.8556\n","Epoch 18/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.8327 - val_loss: 0.3867 - val_accuracy: 0.8444\n","Epoch 19/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.8327 - val_loss: 0.3864 - val_accuracy: 0.8556\n","Epoch 20/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8290 - val_loss: 0.3859 - val_accuracy: 0.8556\n","Epoch 21/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8302 - val_loss: 0.3838 - val_accuracy: 0.8556\n","Epoch 22/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.8277 - val_loss: 0.3838 - val_accuracy: 0.8444\n","Epoch 23/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8290 - val_loss: 0.3830 - val_accuracy: 0.8444\n","Epoch 24/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8290 - val_loss: 0.3848 - val_accuracy: 0.8667\n","Epoch 25/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8340 - val_loss: 0.3818 - val_accuracy: 0.8556\n","Epoch 26/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8302 - val_loss: 0.3816 - val_accuracy: 0.8556\n","Epoch 27/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8340 - val_loss: 0.3810 - val_accuracy: 0.8444\n","Epoch 28/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8277 - val_loss: 0.3819 - val_accuracy: 0.8556\n","Epoch 29/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8315 - val_loss: 0.3800 - val_accuracy: 0.8556\n","Epoch 30/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8352 - val_loss: 0.3798 - val_accuracy: 0.8556\n","Epoch 31/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8265 - val_loss: 0.3816 - val_accuracy: 0.8333\n","Epoch 32/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8352 - val_loss: 0.3800 - val_accuracy: 0.8444\n","Epoch 33/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8227 - val_loss: 0.3810 - val_accuracy: 0.8556\n","Epoch 34/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.8315 - val_loss: 0.3785 - val_accuracy: 0.8556\n","Epoch 35/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8290 - val_loss: 0.3776 - val_accuracy: 0.8556\n","Epoch 36/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.8290 - val_loss: 0.3777 - val_accuracy: 0.8556\n","Epoch 37/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.8290 - val_loss: 0.3776 - val_accuracy: 0.8556\n","Epoch 38/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8277 - val_loss: 0.3771 - val_accuracy: 0.8556\n","Epoch 39/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8315 - val_loss: 0.3773 - val_accuracy: 0.8444\n","Epoch 40/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8327 - val_loss: 0.3793 - val_accuracy: 0.8556\n","Epoch 41/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8290 - val_loss: 0.3769 - val_accuracy: 0.8556\n","Epoch 42/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8277 - val_loss: 0.3762 - val_accuracy: 0.8444\n","Epoch 43/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8302 - val_loss: 0.3773 - val_accuracy: 0.8556\n","Epoch 44/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8302 - val_loss: 0.3761 - val_accuracy: 0.8444\n","Epoch 45/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8327 - val_loss: 0.3748 - val_accuracy: 0.8444\n","Epoch 46/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8365 - val_loss: 0.3745 - val_accuracy: 0.8444\n","Epoch 47/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8302 - val_loss: 0.3765 - val_accuracy: 0.8556\n","Epoch 48/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8302 - val_loss: 0.3737 - val_accuracy: 0.8444\n","Epoch 49/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8327 - val_loss: 0.3732 - val_accuracy: 0.8444\n","Epoch 50/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8090 - val_loss: 0.3763 - val_accuracy: 0.8333\n","Epoch 51/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.8352 - val_loss: 0.3715 - val_accuracy: 0.8444\n","Epoch 52/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8340 - val_loss: 0.3713 - val_accuracy: 0.8556\n","Epoch 53/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8315 - val_loss: 0.3709 - val_accuracy: 0.8444\n","Epoch 54/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8327 - val_loss: 0.3717 - val_accuracy: 0.8667\n","Epoch 55/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8302 - val_loss: 0.3709 - val_accuracy: 0.8444\n","Epoch 56/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8302 - val_loss: 0.3698 - val_accuracy: 0.8444\n","Epoch 57/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8302 - val_loss: 0.3721 - val_accuracy: 0.8556\n","Epoch 58/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8315 - val_loss: 0.3699 - val_accuracy: 0.8444\n","Epoch 59/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8377 - val_loss: 0.3696 - val_accuracy: 0.8444\n","Epoch 60/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8302 - val_loss: 0.3719 - val_accuracy: 0.8556\n","Epoch 61/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8327 - val_loss: 0.3698 - val_accuracy: 0.8556\n","Epoch 62/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8277 - val_loss: 0.3688 - val_accuracy: 0.8444\n","Epoch 63/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8365 - val_loss: 0.3681 - val_accuracy: 0.8444\n","Epoch 64/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8327 - val_loss: 0.3676 - val_accuracy: 0.8444\n","Epoch 65/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8277 - val_loss: 0.3676 - val_accuracy: 0.8444\n","Epoch 66/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8277 - val_loss: 0.3656 - val_accuracy: 0.8444\n","Epoch 67/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8340 - val_loss: 0.3660 - val_accuracy: 0.8444\n","Epoch 68/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8340 - val_loss: 0.3680 - val_accuracy: 0.8444\n","Epoch 69/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8315 - val_loss: 0.3696 - val_accuracy: 0.8667\n","Epoch 70/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8290 - val_loss: 0.3671 - val_accuracy: 0.8444\n","Epoch 71/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8302 - val_loss: 0.3685 - val_accuracy: 0.8444\n","Epoch 72/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8302 - val_loss: 0.3671 - val_accuracy: 0.8444\n","Epoch 73/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8327 - val_loss: 0.3665 - val_accuracy: 0.8444\n","Epoch 74/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8302 - val_loss: 0.3674 - val_accuracy: 0.8556\n","Epoch 75/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8315 - val_loss: 0.3659 - val_accuracy: 0.8444\n","Epoch 76/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.8290 - val_loss: 0.3635 - val_accuracy: 0.8444\n","Epoch 77/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8352 - val_loss: 0.3635 - val_accuracy: 0.8444\n","Epoch 78/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8390 - val_loss: 0.3669 - val_accuracy: 0.8556\n","Epoch 79/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8290 - val_loss: 0.3649 - val_accuracy: 0.8556\n","Epoch 80/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8340 - val_loss: 0.3638 - val_accuracy: 0.8444\n","Epoch 81/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8302 - val_loss: 0.3656 - val_accuracy: 0.8556\n","Epoch 82/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8290 - val_loss: 0.3632 - val_accuracy: 0.8444\n","Epoch 83/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8340 - val_loss: 0.3628 - val_accuracy: 0.8444\n","Epoch 84/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8315 - val_loss: 0.3656 - val_accuracy: 0.8556\n","Epoch 85/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8290 - val_loss: 0.3629 - val_accuracy: 0.8556\n","Epoch 86/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8352 - val_loss: 0.3616 - val_accuracy: 0.8444\n","Epoch 87/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8340 - val_loss: 0.3646 - val_accuracy: 0.8556\n","Epoch 88/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8302 - val_loss: 0.3637 - val_accuracy: 0.8556\n","Epoch 89/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8302 - val_loss: 0.3617 - val_accuracy: 0.8444\n","Epoch 90/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8352 - val_loss: 0.3619 - val_accuracy: 0.8444\n","Epoch 91/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8302 - val_loss: 0.3640 - val_accuracy: 0.8667\n","Epoch 92/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8302 - val_loss: 0.3590 - val_accuracy: 0.8556\n","Epoch 93/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8365 - val_loss: 0.3597 - val_accuracy: 0.8556\n","Epoch 94/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8302 - val_loss: 0.3617 - val_accuracy: 0.8556\n","Epoch 95/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8315 - val_loss: 0.3593 - val_accuracy: 0.8444\n","Epoch 96/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.4045 - accuracy: 0.8340 - val_loss: 0.3602 - val_accuracy: 0.8444\n","Epoch 97/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8277 - val_loss: 0.3605 - val_accuracy: 0.8444\n","Epoch 98/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8352 - val_loss: 0.3592 - val_accuracy: 0.8444\n","Epoch 99/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8290 - val_loss: 0.3625 - val_accuracy: 0.8667\n","Epoch 100/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8265 - val_loss: 0.3586 - val_accuracy: 0.8444\n","Epoch 101/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8352 - val_loss: 0.3615 - val_accuracy: 0.8556\n","Epoch 102/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8302 - val_loss: 0.3592 - val_accuracy: 0.8444\n","Epoch 103/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8327 - val_loss: 0.3591 - val_accuracy: 0.8444\n","Epoch 104/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8302 - val_loss: 0.3593 - val_accuracy: 0.8556\n","Epoch 105/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8327 - val_loss: 0.3580 - val_accuracy: 0.8444\n","Epoch 106/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8302 - val_loss: 0.3605 - val_accuracy: 0.8556\n","Epoch 107/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8315 - val_loss: 0.3562 - val_accuracy: 0.8444\n","Epoch 108/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8365 - val_loss: 0.3556 - val_accuracy: 0.8444\n","Epoch 109/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8327 - val_loss: 0.3612 - val_accuracy: 0.8556\n","Epoch 110/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8277 - val_loss: 0.3577 - val_accuracy: 0.8444\n","Epoch 111/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8315 - val_loss: 0.3561 - val_accuracy: 0.8444\n","Epoch 112/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8327 - val_loss: 0.3587 - val_accuracy: 0.8556\n","Epoch 113/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8365 - val_loss: 0.3553 - val_accuracy: 0.8444\n","Epoch 114/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8377 - val_loss: 0.3572 - val_accuracy: 0.8556\n","Epoch 115/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8290 - val_loss: 0.3580 - val_accuracy: 0.8667\n","Epoch 116/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8327 - val_loss: 0.3547 - val_accuracy: 0.8444\n","Epoch 117/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8352 - val_loss: 0.3573 - val_accuracy: 0.8556\n","Epoch 118/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8352 - val_loss: 0.3589 - val_accuracy: 0.8667\n","Epoch 119/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8302 - val_loss: 0.3561 - val_accuracy: 0.8556\n","Epoch 120/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8340 - val_loss: 0.3592 - val_accuracy: 0.8556\n","Epoch 121/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8315 - val_loss: 0.3573 - val_accuracy: 0.8556\n","Epoch 122/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8290 - val_loss: 0.3566 - val_accuracy: 0.8444\n","Epoch 123/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8290 - val_loss: 0.3566 - val_accuracy: 0.8667\n","Epoch 124/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8290 - val_loss: 0.3558 - val_accuracy: 0.8556\n","Epoch 125/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8277 - val_loss: 0.3567 - val_accuracy: 0.8667\n","Epoch 126/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8302 - val_loss: 0.3555 - val_accuracy: 0.8444\n","Epoch 127/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8265 - val_loss: 0.3572 - val_accuracy: 0.8556\n","Epoch 128/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8290 - val_loss: 0.3560 - val_accuracy: 0.8444\n","Epoch 129/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8327 - val_loss: 0.3548 - val_accuracy: 0.8444\n","Epoch 130/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8327 - val_loss: 0.3574 - val_accuracy: 0.8556\n","Epoch 131/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.8290 - val_loss: 0.3544 - val_accuracy: 0.8444\n","Epoch 132/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8352 - val_loss: 0.3549 - val_accuracy: 0.8444\n","Epoch 133/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8302 - val_loss: 0.3581 - val_accuracy: 0.8556\n","Epoch 134/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8302 - val_loss: 0.3555 - val_accuracy: 0.8444\n","Epoch 135/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8290 - val_loss: 0.3559 - val_accuracy: 0.8444\n","Epoch 136/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8277 - val_loss: 0.3558 - val_accuracy: 0.8444\n","Epoch 137/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8290 - val_loss: 0.3553 - val_accuracy: 0.8556\n","Epoch 138/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8327 - val_loss: 0.3543 - val_accuracy: 0.8444\n","Epoch 139/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8315 - val_loss: 0.3543 - val_accuracy: 0.8444\n","Epoch 140/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8277 - val_loss: 0.3544 - val_accuracy: 0.8556\n","Epoch 141/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8290 - val_loss: 0.3553 - val_accuracy: 0.8444\n","Epoch 142/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8340 - val_loss: 0.3527 - val_accuracy: 0.8444\n","Epoch 143/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8290 - val_loss: 0.3529 - val_accuracy: 0.8444\n","Epoch 144/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8327 - val_loss: 0.3541 - val_accuracy: 0.8556\n","Epoch 145/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8327 - val_loss: 0.3554 - val_accuracy: 0.8556\n","Epoch 146/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8290 - val_loss: 0.3519 - val_accuracy: 0.8444\n","Epoch 147/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8327 - val_loss: 0.3533 - val_accuracy: 0.8444\n","Epoch 148/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8277 - val_loss: 0.3527 - val_accuracy: 0.8444\n","Epoch 149/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8352 - val_loss: 0.3519 - val_accuracy: 0.8556\n","Epoch 150/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8315 - val_loss: 0.3536 - val_accuracy: 0.8556\n","Epoch 151/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8327 - val_loss: 0.3511 - val_accuracy: 0.8444\n","Epoch 152/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8377 - val_loss: 0.3523 - val_accuracy: 0.8444\n","Epoch 153/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8302 - val_loss: 0.3539 - val_accuracy: 0.8667\n","Epoch 154/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8302 - val_loss: 0.3517 - val_accuracy: 0.8444\n","Epoch 155/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8290 - val_loss: 0.3559 - val_accuracy: 0.8556\n","Epoch 156/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8365 - val_loss: 0.3537 - val_accuracy: 0.8556\n","Epoch 157/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8315 - val_loss: 0.3522 - val_accuracy: 0.8444\n","Epoch 158/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8327 - val_loss: 0.3514 - val_accuracy: 0.8444\n","Epoch 159/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8327 - val_loss: 0.3528 - val_accuracy: 0.8556\n","Epoch 160/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8302 - val_loss: 0.3511 - val_accuracy: 0.8444\n","Epoch 161/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8290 - val_loss: 0.3548 - val_accuracy: 0.8556\n","Epoch 162/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8277 - val_loss: 0.3499 - val_accuracy: 0.8444\n","Epoch 163/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8340 - val_loss: 0.3521 - val_accuracy: 0.8444\n","Epoch 164/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8290 - val_loss: 0.3523 - val_accuracy: 0.8667\n","Epoch 165/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8315 - val_loss: 0.3508 - val_accuracy: 0.8444\n","Epoch 166/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8340 - val_loss: 0.3573 - val_accuracy: 0.8444\n","Epoch 167/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8327 - val_loss: 0.3504 - val_accuracy: 0.8444\n","Epoch 168/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8340 - val_loss: 0.3502 - val_accuracy: 0.8444\n","Epoch 169/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8315 - val_loss: 0.3513 - val_accuracy: 0.8444\n","Epoch 170/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8302 - val_loss: 0.3522 - val_accuracy: 0.8444\n","Epoch 171/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8327 - val_loss: 0.3500 - val_accuracy: 0.8556\n","Epoch 172/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8265 - val_loss: 0.3546 - val_accuracy: 0.8556\n","Epoch 173/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8302 - val_loss: 0.3517 - val_accuracy: 0.8444\n","Epoch 174/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8327 - val_loss: 0.3515 - val_accuracy: 0.8444\n","Epoch 175/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8277 - val_loss: 0.3529 - val_accuracy: 0.8556\n","Epoch 176/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8277 - val_loss: 0.3521 - val_accuracy: 0.8556\n","Epoch 177/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8290 - val_loss: 0.3515 - val_accuracy: 0.8556\n","Epoch 178/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8302 - val_loss: 0.3498 - val_accuracy: 0.8444\n","Epoch 179/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8315 - val_loss: 0.3545 - val_accuracy: 0.8444\n","Epoch 180/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8315 - val_loss: 0.3491 - val_accuracy: 0.8444\n","Epoch 181/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8302 - val_loss: 0.3508 - val_accuracy: 0.8556\n","Epoch 182/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8277 - val_loss: 0.3531 - val_accuracy: 0.8556\n","Epoch 183/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8315 - val_loss: 0.3510 - val_accuracy: 0.8667\n","Epoch 184/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8327 - val_loss: 0.3494 - val_accuracy: 0.8444\n","Epoch 185/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8290 - val_loss: 0.3557 - val_accuracy: 0.8444\n","Epoch 186/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8302 - val_loss: 0.3516 - val_accuracy: 0.8667\n","Epoch 187/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8265 - val_loss: 0.3477 - val_accuracy: 0.8444\n","Epoch 188/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8227 - val_loss: 0.3583 - val_accuracy: 0.8333\n","Epoch 189/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8265 - val_loss: 0.3463 - val_accuracy: 0.8444\n","Epoch 190/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8352 - val_loss: 0.3503 - val_accuracy: 0.8556\n","Epoch 191/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8277 - val_loss: 0.3500 - val_accuracy: 0.8444\n","Epoch 192/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8290 - val_loss: 0.3499 - val_accuracy: 0.8556\n","Epoch 193/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8315 - val_loss: 0.3505 - val_accuracy: 0.8556\n","Epoch 194/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8265 - val_loss: 0.3511 - val_accuracy: 0.8667\n","Epoch 195/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8265 - val_loss: 0.3496 - val_accuracy: 0.8444\n","Epoch 196/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8327 - val_loss: 0.3497 - val_accuracy: 0.8556\n","Epoch 197/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8315 - val_loss: 0.3512 - val_accuracy: 0.8556\n","Epoch 198/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8302 - val_loss: 0.3504 - val_accuracy: 0.8444\n","Epoch 199/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8302 - val_loss: 0.3507 - val_accuracy: 0.8556\n","Epoch 200/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8302 - val_loss: 0.3504 - val_accuracy: 0.8444\n","Epoch 201/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8240 - val_loss: 0.3548 - val_accuracy: 0.8556\n","Epoch 202/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8352 - val_loss: 0.3488 - val_accuracy: 0.8444\n","Epoch 203/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8265 - val_loss: 0.3480 - val_accuracy: 0.8444\n","Epoch 204/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8352 - val_loss: 0.3560 - val_accuracy: 0.8333\n","Epoch 205/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8327 - val_loss: 0.3508 - val_accuracy: 0.8667\n","Epoch 206/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8277 - val_loss: 0.3483 - val_accuracy: 0.8556\n","Epoch 207/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8352 - val_loss: 0.3478 - val_accuracy: 0.8556\n","Epoch 208/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8315 - val_loss: 0.3510 - val_accuracy: 0.8667\n","Epoch 209/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8277 - val_loss: 0.3483 - val_accuracy: 0.8556\n","Epoch 210/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8302 - val_loss: 0.3489 - val_accuracy: 0.8556\n","Epoch 211/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8327 - val_loss: 0.3517 - val_accuracy: 0.8556\n","Epoch 212/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8315 - val_loss: 0.3510 - val_accuracy: 0.8556\n","Epoch 213/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8327 - val_loss: 0.3478 - val_accuracy: 0.8556\n","Epoch 214/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8302 - val_loss: 0.3496 - val_accuracy: 0.8444\n","Epoch 215/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8302 - val_loss: 0.3481 - val_accuracy: 0.8444\n","Epoch 216/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8340 - val_loss: 0.3488 - val_accuracy: 0.8444\n","Epoch 217/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8277 - val_loss: 0.3502 - val_accuracy: 0.8556\n","Epoch 218/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8277 - val_loss: 0.3498 - val_accuracy: 0.8444\n","Epoch 219/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8315 - val_loss: 0.3487 - val_accuracy: 0.8556\n","Epoch 220/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8302 - val_loss: 0.3537 - val_accuracy: 0.8667\n","Epoch 221/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8327 - val_loss: 0.3479 - val_accuracy: 0.8556\n","Epoch 222/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8327 - val_loss: 0.3476 - val_accuracy: 0.8556\n","Epoch 223/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8315 - val_loss: 0.3562 - val_accuracy: 0.8556\n","Epoch 224/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8315 - val_loss: 0.3482 - val_accuracy: 0.8444\n","Epoch 225/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8302 - val_loss: 0.3479 - val_accuracy: 0.8556\n","Epoch 226/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8302 - val_loss: 0.3514 - val_accuracy: 0.8556\n","Epoch 227/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8340 - val_loss: 0.3501 - val_accuracy: 0.8444\n","Epoch 228/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8352 - val_loss: 0.3487 - val_accuracy: 0.8556\n","Epoch 229/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8290 - val_loss: 0.3560 - val_accuracy: 0.8667\n","Epoch 230/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8340 - val_loss: 0.3506 - val_accuracy: 0.8556\n","Epoch 231/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8277 - val_loss: 0.3503 - val_accuracy: 0.8556\n","Epoch 232/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8290 - val_loss: 0.3490 - val_accuracy: 0.8556\n","Epoch 233/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8302 - val_loss: 0.3542 - val_accuracy: 0.8556\n","Epoch 234/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8352 - val_loss: 0.3460 - val_accuracy: 0.8556\n","Epoch 235/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8340 - val_loss: 0.3495 - val_accuracy: 0.8556\n","Epoch 236/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8327 - val_loss: 0.3537 - val_accuracy: 0.8556\n","Epoch 237/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8277 - val_loss: 0.3485 - val_accuracy: 0.8444\n","Epoch 238/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8352 - val_loss: 0.3508 - val_accuracy: 0.8444\n","Epoch 239/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8327 - val_loss: 0.3541 - val_accuracy: 0.8556\n","Epoch 240/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8327 - val_loss: 0.3494 - val_accuracy: 0.8444\n","Epoch 241/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8302 - val_loss: 0.3500 - val_accuracy: 0.8556\n","Epoch 242/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8252 - val_loss: 0.3562 - val_accuracy: 0.8444\n","Epoch 243/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8365 - val_loss: 0.3471 - val_accuracy: 0.8556\n","Epoch 244/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8277 - val_loss: 0.3517 - val_accuracy: 0.8556\n","Epoch 245/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8265 - val_loss: 0.3464 - val_accuracy: 0.8556\n","Epoch 246/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8327 - val_loss: 0.3482 - val_accuracy: 0.8556\n","Epoch 247/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8365 - val_loss: 0.3563 - val_accuracy: 0.8667\n","Epoch 248/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8302 - val_loss: 0.3491 - val_accuracy: 0.8556\n","Epoch 249/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8315 - val_loss: 0.3504 - val_accuracy: 0.8556\n","Epoch 250/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8277 - val_loss: 0.3492 - val_accuracy: 0.8556\n","Epoch 251/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8315 - val_loss: 0.3481 - val_accuracy: 0.8444\n","Epoch 252/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8290 - val_loss: 0.3526 - val_accuracy: 0.8556\n","Epoch 253/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8340 - val_loss: 0.3525 - val_accuracy: 0.8667\n","Epoch 254/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8327 - val_loss: 0.3496 - val_accuracy: 0.8556\n","Epoch 255/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8290 - val_loss: 0.3519 - val_accuracy: 0.8556\n","Epoch 256/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8315 - val_loss: 0.3509 - val_accuracy: 0.8556\n","Epoch 257/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8352 - val_loss: 0.3501 - val_accuracy: 0.8556\n","Epoch 258/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8290 - val_loss: 0.3480 - val_accuracy: 0.8556\n","Epoch 259/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8302 - val_loss: 0.3476 - val_accuracy: 0.8556\n","Epoch 260/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8290 - val_loss: 0.3538 - val_accuracy: 0.8444\n","Epoch 261/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8315 - val_loss: 0.3488 - val_accuracy: 0.8556\n","Epoch 262/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8290 - val_loss: 0.3471 - val_accuracy: 0.8444\n","Epoch 263/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8265 - val_loss: 0.3455 - val_accuracy: 0.8556\n","Epoch 264/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8302 - val_loss: 0.3509 - val_accuracy: 0.8556\n","Epoch 265/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8315 - val_loss: 0.3508 - val_accuracy: 0.8556\n","Epoch 266/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8340 - val_loss: 0.3460 - val_accuracy: 0.8556\n","Epoch 267/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8302 - val_loss: 0.3498 - val_accuracy: 0.8556\n","Epoch 268/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8365 - val_loss: 0.3491 - val_accuracy: 0.8556\n","Epoch 269/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8290 - val_loss: 0.3461 - val_accuracy: 0.8556\n","Epoch 270/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8302 - val_loss: 0.3479 - val_accuracy: 0.8667\n","Epoch 271/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8290 - val_loss: 0.3506 - val_accuracy: 0.8556\n","Epoch 272/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8302 - val_loss: 0.3483 - val_accuracy: 0.8556\n","Epoch 273/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8352 - val_loss: 0.3509 - val_accuracy: 0.8556\n","Epoch 274/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8290 - val_loss: 0.3481 - val_accuracy: 0.8667\n","Epoch 275/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8352 - val_loss: 0.3480 - val_accuracy: 0.8556\n","Epoch 276/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8302 - val_loss: 0.3487 - val_accuracy: 0.8444\n","Epoch 277/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8315 - val_loss: 0.3490 - val_accuracy: 0.8556\n","Epoch 278/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8277 - val_loss: 0.3476 - val_accuracy: 0.8667\n","Epoch 279/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8315 - val_loss: 0.3517 - val_accuracy: 0.8444\n","Epoch 280/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8252 - val_loss: 0.3465 - val_accuracy: 0.8556\n","Epoch 281/300\n","7/7 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8265 - val_loss: 0.3540 - val_accuracy: 0.8444\n","Epoch 282/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8315 - val_loss: 0.3476 - val_accuracy: 0.8556\n","Epoch 283/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8302 - val_loss: 0.3496 - val_accuracy: 0.8667\n","Epoch 284/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8352 - val_loss: 0.3495 - val_accuracy: 0.8556\n","Epoch 285/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8340 - val_loss: 0.3478 - val_accuracy: 0.8556\n","Epoch 286/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8290 - val_loss: 0.3519 - val_accuracy: 0.8556\n","Epoch 287/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8315 - val_loss: 0.3489 - val_accuracy: 0.8667\n","Epoch 288/300\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8390 - val_loss: 0.3531 - val_accuracy: 0.8444\n","Epoch 289/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8302 - val_loss: 0.3498 - val_accuracy: 0.8556\n","Epoch 290/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8377 - val_loss: 0.3501 - val_accuracy: 0.8556\n","Epoch 291/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8315 - val_loss: 0.3491 - val_accuracy: 0.8667\n","Epoch 292/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8290 - val_loss: 0.3493 - val_accuracy: 0.8556\n","Epoch 293/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8315 - val_loss: 0.3508 - val_accuracy: 0.8556\n","Epoch 294/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8277 - val_loss: 0.3488 - val_accuracy: 0.8667\n","Epoch 295/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8327 - val_loss: 0.3530 - val_accuracy: 0.8556\n","Epoch 296/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8414 - val_loss: 0.3492 - val_accuracy: 0.8556\n","Epoch 297/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8302 - val_loss: 0.3512 - val_accuracy: 0.8556\n","Epoch 298/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8340 - val_loss: 0.3527 - val_accuracy: 0.8556\n","Epoch 299/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8327 - val_loss: 0.3486 - val_accuracy: 0.8556\n","Epoch 300/300\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8302 - val_loss: 0.3492 - val_accuracy: 0.8556\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7faaa7e0be90>"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["score = mlp_classifier.evaluate(X_train, Y_train, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltcCnh9uQRHl","executionInfo":{"status":"ok","timestamp":1650380211122,"user_tz":240,"elapsed":320,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"533af3dd-c61d-40f1-dcee-2f4551915cba"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.38406550884246826\n","Test accuracy: 0.8338944911956787\n"]}]},{"cell_type":"code","source":["# Prediction\n","Y_pred = mlp_classifier.predict(X_test)"],"metadata":{"id":"q6123qR5QfdR","executionInfo":{"status":"ok","timestamp":1650380213367,"user_tz":240,"elapsed":312,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["y_final = (Y_pred > 0.5).astype(int).reshape(X_test.shape[0])\n","\n","output = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_final})\n","output.to_csv('prediction.csv', index=False)\n"],"metadata":{"id":"LtabZCLbU5OC","executionInfo":{"status":"ok","timestamp":1650380271626,"user_tz":240,"elapsed":313,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}}},"execution_count":36,"outputs":[]}]}